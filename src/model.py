import tensorflow as tf
from tensorflow_examples.models.pix2pix import pix2pix

def model_compile():
    # Define the base model
    base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)

    # Use the activations of these layers
    layer_names = [
        'block_1_expand_relu',   # 64x64
        'block_3_expand_relu',   # 32x32
        'block_6_expand_relu',   # 16x16
        'block_13_expand_relu',  # 8x8
        'block_16_project',      # 4x4
    ]
    base_model_outputs = [base_model.get_layer(name).output for name in layer_names]

    # Create the feature extraction model
    down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)

    down_stack.trainable = False

    # Create the decoder/upsampler
    up_stack = [
        pix2pix.upsample(512, 3),  # 4x4 -> 8x8
        pix2pix.upsample(256, 3),  # 8x8 -> 16x16
        pix2pix.upsample(128, 3),  # 16x16 -> 32x32
        pix2pix.upsample(64, 3),   # 32x32 -> 64x64
    ]

    def unet_model(output_channels:int):
        """Create a U-Net model with a specific number of output channels."""
        inputs = tf.keras.layers.Input(shape=[128, 128, 3])

        # Downsampling through the model
        x = inputs
        skips = []
        for filter_size in [64, 128, 256, 512]:
            x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)
            x = tf.keras.layers.BatchNormalization()(x)
            x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)
            x = tf.keras.layers.BatchNormalization()(x)
            skips.append(x)
            x = tf.keras.layers.MaxPooling2D(2)(x)
            x = tf.keras.layers.Dropout(0.5)(x)

        # Middle part of the network
        x = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Dropout(0.5)(x)

        # Upsampling and establishing the skip connections
        skips = reversed(skips)
        for filter_size, skip in zip([512, 256, 128, 64], skips):
            x = tf.keras.layers.Conv2DTranspose(filter_size, 2, strides=2, padding='same')(x)
            concat = tf.keras.layers.Concatenate()
            x = concat([x, skip])
            x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)
            x = tf.keras.layers.BatchNormalization()(x)
            x = tf.keras.layers.Conv2D(filter_size, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)
            x = tf.keras.layers.BatchNormalization()(x)

        # This is the last layer of the model
        last = tf.keras.layers.Conv2D(output_channels, 3, padding='same')  # Maintain 128x128 resolution

        x = last(x)

        return tf.keras.Model(inputs=inputs, outputs=x)

    # The model is saved in the models directory
    model = tf.keras.models.load_model('/Users/devynmiller/the-final-assignment2-cpsc542/models/unet-model.h5')
    

    # Plot the resulting model architecture

    tf.keras.utils.plot_model(model, show_shapes=True)
    return model
